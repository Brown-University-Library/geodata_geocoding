{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Census Batch Geocoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See [https://geocoding.geo.census.gov/geocoder/Geocoding_Services_API.pdf](https://geocoding.geo.census.gov/geocoder/Geocoding_Services_API.pdf) for more information.\n",
    "\n",
    "The Census batch geocoder is a great solution when you need to geocode high quantities of addresses located in the United States. We can submit a file containing up to 10,000 addresses at a time. The file needs to be formatted correctly with the following columns: Unique ID, Street address, City, State, ZIP. We do this preprocessing below, and subsequently write the CSV to file. We then send a GET request for the file using the `curl` utility to get the locations of the addresses. Change the variable names to fit your file format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "addfile='RI_Independent_Schools.csv' #Input file with addresses\n",
    "df = pd.read_csv(addfile)\n",
    "\n",
    "ID = 'org_ID'\n",
    "NAME = 'name'\n",
    "ADDRESS = 'location_address1'\n",
    "STATE = 'location_state'\n",
    "CITY = 'location_city'\n",
    "ZIP = 'location_zip'\n",
    "MAX_LOCATIONS = 5\n",
    "\n",
    "def split_dataframe(df, chunk_size=10000):\n",
    "    return [df[i:i + chunk_size] for i in range(0, len(df), chunk_size)]\n",
    "\n",
    "def preprocess(df: pd.DataFrame) -> pd.DataFrame | list[pd.DataFrame]:\n",
    "    df[ADDRESS] = df[ADDRESS].str.replace('One', '1')\n",
    "    if len(df) > 10000:\n",
    "        df = split_dataframe(df)\n",
    "    return df\n",
    "\n",
    "batch_compatible_df = df[[ID, ADDRESS, CITY, STATE, ZIP]]\n",
    "batch_compatible_df.to_csv(f'Batch_Compatible_{addfile}', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We specify a benchmark parameter, which is a numerical ID or name which references the version of the locator to be\n",
    "used. This generally corresponds to address locators based on MAF/TIGER benchmarks, otherwise known as TIGER/Line geography. At the time of writing, there were three benchmarks available:\n",
    "- 4: Public Address Ranges - Current Benchmark\n",
    "- 8: Public Address Ranges - ACS2024 Benchmark\n",
    "- 2020: Public Address Ranges - Census 2020 Benchmark\n",
    "\n",
    "The differences are usually minimal; we will stick to the default here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 13043  100  9694  100  3349   7236   2500  0:00:01  0:00:01 --:--:--  9740\n"
     ]
    }
   ],
   "source": [
    "!curl --form addressFile=@Batch_Compatible_RI_Independent_Schools.csv --form benchmark=4 \\\n",
    "https://geocoding.geo.census.gov/geocoder/locations/addressbatch --output Batch_Compatible_RI_Independent_Schools_Matched.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Census Individual Geocoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Census Batch geocoder defined above should be your go-to in most cases: it runs much faster and provides easy access to results. However, in some cases the format specified above may not be a good fit for the data attributes you have. You may also want more control over the process, or to look at the matches for an individual address. In this case, individual geocoding may be a better choice. Here, we will use the Census API's One Line Address feature to lookup addresses built from individual rows. One Line Address lookup can match based on just two fields, the ADDRESS and ZIP fields. \n",
    "\n",
    "First, we define a function which will query the API for the Street, City, Address, and Zip provided in each row. We default to the current benchmark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#can provide: (street, zip), (street, city, state) or more information.\n",
    "import requests, urllib, traceback\n",
    "\n",
    "address = '201 Thayer St,Providence,RI'\n",
    "lineaddr_url = f'https://geocoding.geo.census.gov/geocoder/locations/onelineaddress?'\n",
    "\n",
    "addfile='RI_Independent_Schools.csv' #Input file with addresses\n",
    "df = pd.read_csv(addfile)\n",
    "\n",
    "def get_request_census(address: str, url: str) -> list[dict]:\n",
    "    address = urllib.parse.quote_plus(address)\n",
    "    add_url = f'address={address}&benchmark=4&format=json'\n",
    "    data_url = f'{lineaddr_url}{add_url}'\n",
    "    #print(data_url)\n",
    "    response=requests.get(data_url)\n",
    "    return response.json()['result']['addressMatches']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we construct the address string from the ADDRESS, CITY, STATE, and ZIP columns defined above. We send a GET request for each row of the dataframe. We retrieve best matching address, x, and y coordinates unless there are no matches. We append four columns to the dataframe specifying the new information. If there were no matches, we set them to None instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, row in tqdm(df.iterrows(), total=len(df)):\n",
    "    try:\n",
    "        address = f'{row[ADDRESS]},{row[CITY]},{row[STATE]},{row[ZIP]}'\n",
    "        request_data = get_request_census(address, lineaddr_url)\n",
    "        if len(request_data) > 0:\n",
    "            matches = []\n",
    "            for m in request_data:\n",
    "                matches.append([row[ID], row[NAME], \n",
    "                                    m['matchedAddress'], \n",
    "                                    m['coordinates']['x'],\n",
    "                                    m['coordinates']['y']])\n",
    "            matches.sort(key=lambda x: x[2], reverse=True)\n",
    "            best_match = matches[0]\n",
    "            match_ct = len(request_data)\n",
    "            match_address,x,y = best_match[2:5]\n",
    "        else:\n",
    "            score,match_address,x,y = None,None,None, None\n",
    "        df.loc[idx, 'matches'] = match_ct\n",
    "        df.loc[idx, 'match_address'] = match_address\n",
    "        df.loc[idx, 'x'] = x\n",
    "        df.loc[idx,'y'] = y\n",
    "\n",
    "    except Exception as e:\n",
    "        traceback.print_exc() \n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "csci1470 Python 3.9.13",
   "language": "python",
   "name": "csci1470"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
